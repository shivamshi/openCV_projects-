{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73d5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import imutils\n",
    "#from skvideo.io import VideoWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec7f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd12160",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN=np.load('train.npy')\n",
    "TEST=np.load('test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "576acf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 200,   0, ..., 100, 200,   0],\n",
       "       [100, 200,   0, ..., 100, 200,   0],\n",
       "       [100, 200,   0, ..., 143, 215,  70],\n",
       "       ...,\n",
       "       [100, 200,   0, ..., 100, 200,   0],\n",
       "       [100, 200,   0, ..., 100, 200,   0],\n",
       "       [100, 200,   0, ..., 100, 200,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f290ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e370a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29043fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(TRAIN,TEST,test_size=0.30)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e0ad53a",
   "metadata": {},
   "source": [
    "r = RandomForestClassifier(n_estimators=600)\n",
    "r.fit(x_train,y_train)\n",
    "y_pred=r.predict(x_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46190090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pytho\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9359504132231405"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76974173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       345\n",
      "         1.0       0.90      0.88      0.89       139\n",
      "\n",
      "    accuracy                           0.94       484\n",
      "   macro avg       0.92      0.92      0.92       484\n",
      "weighted avg       0.94      0.94      0.94       484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5a5ee5f",
   "metadata": {},
   "source": [
    "op=SVC()\n",
    "op.fit(x_train,y_train)\n",
    "y_pred=op.predict(x_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21a96cb6",
   "metadata": {},
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03148daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lol=1\n",
    "font=cv2.FONT_HERSHEY_COMPLEX\n",
    "d={1:'MASK',0:'No Mask'}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8995330",
   "metadata": {},
   "source": [
    "output = 'example.avi'\n",
    "video = 'output.mp4'\n",
    "fps = 33\n",
    "codec ='MJPG'\n",
    "vs = cv2.VideoCapture(\"C:/Users/pytho/Videos/AA.mp4\")\n",
    "#vs=cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*codec) \n",
    "writer = None\n",
    "(h, w) = (None, None)\n",
    "zeros = None\n",
    "\n",
    "while True:\n",
    "    flag, img = vs.read()\n",
    "    if flag:\n",
    "        img = imutils.resize(img, width=1000)\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5,minSize=(30, 30))\n",
    "        for x,y,w,h in faces:        \n",
    "             #frame=cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),4)\n",
    "            face=img[y:y+h,x:x+w,:]\n",
    "            face=cv2.resize(face,(100,100))\n",
    "            face=face.reshape(1,-1)\n",
    "            pred=lr.predict(face)[0]\n",
    "            n=int(pred)\n",
    "            m=d[n]\n",
    "            if n==0: cv2.putText(img,m,(x,y),font,1,(0,0,255),2)\n",
    "            if n==1: cv2.putText(img,m,(x,y),font,1,(0,255,0),2)\n",
    "                \n",
    "                \n",
    "        cv2.imshow('hell0_world',img)\n",
    "        if cv2.waitKey(lol) & 0xFF==27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "'''    if writer is None:\n",
    "        (h, w) = img.shape[:2]\n",
    "        writer = cv2.VideoWriter(output, fourcc, fps,(w, h), True)\n",
    "    output = np.zeros((h,w,3), dtype=\"uint8\")\n",
    "    #img=cv2.resize(img,(800,500))\n",
    "    output[0:h, 0:w] = img\n",
    "    writer.write(output)\n",
    "    cv2.imshow(\"Output\", output)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:\n",
    "        break'''\n",
    "cv2.destroyAllWindows()\n",
    "vs.release()\n",
    "#writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89788a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(\"C:/Users/pytho/Videos/AA.mp4\")\n",
    "#frame_width=int(cap.get(3))\n",
    "#frame_height=int(cap.get(4))\n",
    "frame_width = int( cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height =int( cap.get( cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "#fourcc = cv2.VideoWriter_fourcc(*\"DIVX\")\n",
    "fourcc=cv2.VideoWriter_fourcc('M','P','E','G')\n",
    "out=cv2.VideoWriter('amgent.avi',fourcc,10,(frame_width,frame_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e357ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap=cv2.VideoCapture(0)\n",
    "#cap=cv2.VideoCapture(r\"C:\\Users\\pytho\\Videos\\AA.mp4\")\n",
    "#cap=cv2.VideoCapture(\"C:/Users/pytho/Downloads/new.mp4\")\n",
    "#cap=cv2.VideoCapture(r'Videos/video.mp4')\n",
    "#cap=cv2.VideoCapture(\"C:/Users/pytho/Downloads/PRE.mp4\")\n",
    "#cap=cv2.VideoCapture(\"C:/Users/pytho/Videos/AA.mp4\")\n",
    "#cap=cv2.VideoCapture(\"C:/Users/pytho/Downloads/nig.mp4\")\n",
    "while True:\n",
    "    flag,img=cap.read()\n",
    "    #cv2.imshow('dsf',img)\n",
    "    if flag:\n",
    "        img = imutils.resize(img, width=1000)\n",
    "        #img=cv2.resize(img,(800,500))\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        #faces=face_cascade.detectMultiScale(gray,1.1,4)\n",
    "        faces = face_cascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5,minSize=(30, 30))\n",
    "        for x,y,w,h in faces:\n",
    "            \n",
    "            frame=cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),4)\n",
    "            #frame = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "            face=img[y:y+h,x:x+w,:]\n",
    "            face=cv2.resize(face,(100,100))\n",
    "            face=face.reshape(1,-1)\n",
    "            pred=lr.predict(face)[0]\n",
    "            n=int(pred)\n",
    "            m=d[n]\n",
    "            if n==0: cv2.putText(img,m,(x,y),font,1,(0,0,255),2)\n",
    "            if n==1: cv2.putText(img,m,(x,y),font,1,(0,255,0),2)\n",
    "            out.write(frame)\n",
    "        cv2.imshow('hell0_world',img)\n",
    "        if cv2.waitKey(lol) & 0xFF==27:\n",
    "            break\n",
    "    else: break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
